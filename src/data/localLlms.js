export const LOCAL_LLM_MODELS = [
  {
    model: "mistral-nemo 12B",
    zielEinsatz: "General Reasoning",
    openWeights: 5,
    openSource: 5,
    trainingsdatenOffen: 2,
    fineTunedBase: "Mistral Base",
    text: 5,
    bild: "N/A",
    ocr: "N/A",
    deutsch: 4,
    zusammenfassen: 4,
    medizinIcd: 3,
    agenticToolUse: 4,
    pro: "stabil, logisch",
    contra: "kein Vision",
    vramMin: "12 GB",
    vramOptimal: "16 GB",
  },
  {
    model: "mistral-small 3.1",
    zielEinsatz: "Agenten / Planung",
    openWeights: 5,
    openSource: 5,
    trainingsdatenOffen: 2,
    fineTunedBase: "Mistral Small",
    text: 5,
    bild: "N/A",
    ocr: "N/A",
    deutsch: 4,
    zusammenfassen: 5,
    medizinIcd: 3,
    agenticToolUse: 5,
    pro: "bestes Agenten-LLM",
    contra: "groß",
    vramMin: "16 GB",
    vramOptimal: "24 GB",
  },
  {
    model: "mistral 7B instruct",
    zielEinsatz: "Leichtes Chat",
    openWeights: 5,
    openSource: 5,
    trainingsdatenOffen: 2,
    fineTunedBase: "Mistral 7B",
    text: 4,
    bild: "N/A",
    ocr: "N/A",
    deutsch: 3,
    zusammenfassen: 3,
    medizinIcd: 2,
    agenticToolUse: 3,
    pro: "sehr schnell",
    contra: "weniger Tiefe",
    vramMin: "8 GB",
    vramOptimal: "12 GB",
  },
  {
    model: "llama 3.1 8B",
    zielEinsatz: "Allround",
    openWeights: 5,
    openSource: 5,
    trainingsdatenOffen: 2,
    fineTunedBase: "Meta LLaMA",
    text: 4,
    bild: "N/A",
    ocr: "N/A",
    deutsch: 4,
    zusammenfassen: 4,
    medizinIcd: 3,
    agenticToolUse: 4,
    pro: "robust",
    contra: "engl. Bias",
    vramMin: "8 GB",
    vramOptimal: "12 GB",
  },
  {
    model: "llama 3.1 8B custom",
    zielEinsatz: "Optimiert lokal",
    openWeights: 5,
    openSource: 5,
    trainingsdatenOffen: 2,
    fineTunedBase: "LLaMA + FT",
    text: 4,
    bild: "N/A",
    ocr: "N/A",
    deutsch: 4,
    zusammenfassen: 4,
    medizinIcd: 3,
    agenticToolUse: 4,
    pro: "gute Prompttreue",
    contra: "FT-abhängig",
    vramMin: "8 GB",
    vramOptimal: "12 GB",
  },
  {
    model: "llama 3.2 vision 11B",
    zielEinsatz: "Vision Allround",
    openWeights: 5,
    openSource: 5,
    trainingsdatenOffen: 2,
    fineTunedBase: "LLaMA Vision",
    text: 4,
    bild: 4,
    ocr: 3,
    deutsch: 3,
    zusammenfassen: 3,
    medizinIcd: 2,
    agenticToolUse: 3,
    pro: "solide Vision",
    contra: "groß",
    vramMin: "12 GB",
    vramOptimal: "16 GB",
  },
  {
    model: "llava 13B",
    zielEinsatz: "Vision QA",
    openWeights: 5,
    openSource: 5,
    trainingsdatenOffen: 2,
    fineTunedBase: "LLaVA",
    text: 3,
    bild: 4,
    ocr: 3,
    deutsch: 3,
    zusammenfassen: 3,
    medizinIcd: 1,
    agenticToolUse: 2,
    pro: "bewährt",
    contra: "alt",
    vramMin: "16 GB",
    vramOptimal: "20 GB",
  },
  {
    model: "qwen 3 14B",
    zielEinsatz: "Generalist",
    openWeights: 5,
    openSource: 5,
    trainingsdatenOffen: 2,
    fineTunedBase: "Qwen 3",
    text: 4,
    bild: "N/A",
    ocr: "N/A",
    deutsch: 3,
    zusammenfassen: 4,
    medizinIcd: 3,
    agenticToolUse: 4,
    pro: "starkes Reasoning",
    contra: "Deutsch mittel",
    vramMin: "16 GB",
    vramOptimal: "20 GB",
  },
  {
    model: "qwen 3 8B",
    zielEinsatz: "Leicht",
    openWeights: 5,
    openSource: 5,
    trainingsdatenOffen: 2,
    fineTunedBase: "Qwen 3",
    text: 3,
    bild: "N/A",
    ocr: "N/A",
    deutsch: 2,
    zusammenfassen: 3,
    medizinIcd: 2,
    agenticToolUse: 3,
    pro: "effizient",
    contra: "limitiert",
    vramMin: "8 GB",
    vramOptimal: "12 GB",
  },
  {
    model: "qwen 2.5 coder 14B",
    zielEinsatz: "Coding / Tools",
    openWeights: 5,
    openSource: 5,
    trainingsdatenOffen: 2,
    fineTunedBase: "Qwen Coder",
    text: 4,
    bild: "N/A",
    ocr: "N/A",
    deutsch: 3,
    zusammenfassen: 3,
    medizinIcd: 2,
    agenticToolUse: 5,
    pro: "bestes Coding",
    contra: "wenig kreativ",
    vramMin: "16 GB",
    vramOptimal: "20 GB",
  },
  {
    model: "qwen 2.5 VL",
    zielEinsatz: "Vision + OCR",
    openWeights: 5,
    openSource: 5,
    trainingsdatenOffen: 2,
    fineTunedBase: "Qwen VL",
    text: 3,
    bild: 4,
    ocr: 4,
    deutsch: 3,
    zusammenfassen: 3,
    medizinIcd: 1,
    agenticToolUse: 3,
    pro: "sehr gutes OCR",
    contra: "Deutsch mittel",
    vramMin: "12 GB",
    vramOptimal: "16 GB",
  },
  {
    model: "qwen 3 VL 4B",
    zielEinsatz: "Vision light",
    openWeights: 5,
    openSource: 5,
    trainingsdatenOffen: 2,
    fineTunedBase: "Qwen VL",
    text: 2,
    bild: 3,
    ocr: 3,
    deutsch: 2,
    zusammenfassen: 2,
    medizinIcd: 1,
    agenticToolUse: 2,
    pro: "klein & schnell",
    contra: "wenig Tiefe",
    vramMin: "6 GB",
    vramOptimal: "8 GB",
  },
  {
    model: "deepseek-r1 7B",
    zielEinsatz: "Reasoning",
    openWeights: 5,
    openSource: 5,
    trainingsdatenOffen: 2,
    fineTunedBase: "DeepSeek R1",
    text: 4,
    bild: "N/A",
    ocr: "N/A",
    deutsch: 3,
    zusammenfassen: 4,
    medizinIcd: 3,
    agenticToolUse: 4,
    pro: "gutes Denken",
    contra: "langsam",
    vramMin: "8 GB",
    vramOptimal: "12 GB",
  },
  {
    model: "deepseek-coder 6.7B",
    zielEinsatz: "Coding",
    openWeights: 5,
    openSource: 5,
    trainingsdatenOffen: 2,
    fineTunedBase: "DeepSeek Coder",
    text: 3,
    bild: "N/A",
    ocr: "N/A",
    deutsch: 2,
    zusammenfassen: 2,
    medizinIcd: 1,
    agenticToolUse: 3,
    pro: "effizient",
    contra: "Deutsch schwach",
    vramMin: "8 GB",
    vramOptimal: "12 GB",
  },
  {
    model: "deepseek-OCR",
    zielEinsatz: "OCR Spezialist",
    openWeights: 5,
    openSource: 4,
    trainingsdatenOffen: 2,
    fineTunedBase: "Vision + OCR FT",
    text: 3,
    bild: 4,
    ocr: 5,
    deutsch: 2,
    zusammenfassen: 3,
    medizinIcd: 1,
    agenticToolUse: 3,
    pro: "bestes OCR lokal",
    contra: "kaum Reasoning",
    vramMin: "8 GB",
    vramOptimal: "12 GB",
  },
  {
    model: "GPT-OSS 20B",
    zielEinsatz: "Agenten / Planung",
    openWeights: 5,
    openSource: 4,
    trainingsdatenOffen: 2,
    fineTunedBase: "GPT-Style",
    text: 5,
    bild: "N/A",
    ocr: "N/A",
    deutsch: 4,
    zusammenfassen: 5,
    medizinIcd: 3,
    agenticToolUse: 5,
    pro: "Top-Agenten-LLM",
    contra: "groß",
    vramMin: "14 GB",
    vramOptimal: "20 GB",
  },
  {
    model: "gemma 3 12B",
    zielEinsatz: "Präzise Antworten",
    openWeights: 5,
    openSource: 5,
    trainingsdatenOffen: 2,
    fineTunedBase: "Gemma 3",
    text: 4,
    bild: "N/A",
    ocr: "N/A",
    deutsch: 3,
    zusammenfassen: 4,
    medizinIcd: 2,
    agenticToolUse: 4,
    pro: "sauber",
    contra: "wenig kreativ",
    vramMin: "12 GB",
    vramOptimal: "16 GB",
  },
  {
    model: "gemma 2 9B",
    zielEinsatz: "Leicht",
    openWeights: 5,
    openSource: 5,
    trainingsdatenOffen: 2,
    fineTunedBase: "Gemma 2",
    text: 3,
    bild: "N/A",
    ocr: "N/A",
    deutsch: 3,
    zusammenfassen: 4,
    medizinIcd: 2,
    agenticToolUse: 3,
    pro: "stabil",
    contra: "begrenzt",
    vramMin: "8 GB",
    vramOptimal: "12 GB",
  },
  {
    model: "gemma 2 2B",
    zielEinsatz: "Edge",
    openWeights: 5,
    openSource: 5,
    trainingsdatenOffen: 2,
    fineTunedBase: "Gemma 2",
    text: 2,
    bild: "N/A",
    ocr: "N/A",
    deutsch: 2,
    zusammenfassen: 2,
    medizinIcd: 1,
    agenticToolUse: 2,
    pro: "extrem klein",
    contra: "sehr limitiert",
    vramMin: "4 GB",
    vramOptimal: "6 GB",
  },
  {
    model: "granite 3.2",
    zielEinsatz: "Business / RAG",
    openWeights: 5,
    openSource: 5,
    trainingsdatenOffen: 2,
    fineTunedBase: "IBM Granite",
    text: 4,
    bild: "N/A",
    ocr: "N/A",
    deutsch: 3,
    zusammenfassen: 4,
    medizinIcd: 2,
    agenticToolUse: 4,
    pro: "kontrollierbar",
    contra: "wenig kreativ",
    vramMin: "8 GB",
    vramOptimal: "12 GB",
  },
  {
    model: "granite 3.2 vision",
    zielEinsatz: "Business Vision",
    openWeights: 5,
    openSource: 5,
    trainingsdatenOffen: 2,
    fineTunedBase: "Granite Vision",
    text: 3,
    bild: 3,
    ocr: 3,
    deutsch: 3,
    zusammenfassen: 3,
    medizinIcd: 1,
    agenticToolUse: 3,
    pro: "stabil",
    contra: "schwache Vision",
    vramMin: "8 GB",
    vramOptimal: "12 GB",
  },
  {
    model: "nemotron mini",
    zielEinsatz: "Edge Agent",
    openWeights: 5,
    openSource: 5,
    trainingsdatenOffen: 2,
    fineTunedBase: "NVIDIA",
    text: 3,
    bild: "N/A",
    ocr: "N/A",
    deutsch: 2,
    zusammenfassen: 2,
    medizinIcd: 1,
    agenticToolUse: 3,
    pro: "sehr schnell",
    contra: "flach",
    vramMin: "6 GB",
    vramOptimal: "8 GB",
  },
  {
    model: "phi-3 3.8B",
    zielEinsatz: "Fast Edge",
    openWeights: 5,
    openSource: 5,
    trainingsdatenOffen: 2,
    fineTunedBase: "Microsoft Phi",
    text: 3,
    bild: "N/A",
    ocr: "N/A",
    deutsch: 2,
    zusammenfassen: 2,
    medizinIcd: 1,
    agenticToolUse: 2,
    pro: "extrem schnell",
    contra: "kaum Tiefe",
    vramMin: "4 GB",
    vramOptimal: "6 GB",
  },
  {
    model: "MedGemma 27B",
    zielEinsatz: "Medizin Spezialist",
    openWeights: 5,
    openSource: 5,
    trainingsdatenOffen: 2,
    fineTunedBase: "Med-FT",
    text: 5,
    bild: "N/A",
    ocr: "N/A",
    deutsch: 3,
    zusammenfassen: 5,
    medizinIcd: 5,
    agenticToolUse: 3,
    pro: "medizinisch stark",
    contra: "sehr groß",
    vramMin: "16 GB (Q4)",
    vramOptimal: "24–32 GB",
  },
  {
    model: "LLaMA3-Med42-8B",
    zielEinsatz: "Klinische Assistenz",
    openWeights: 5,
    openSource: 5,
    trainingsdatenOffen: 2,
    fineTunedBase: "LLaMA + Med FT",
    text: 4,
    bild: "N/A",
    ocr: "N/A",
    deutsch: 3,
    zusammenfassen: 4,
    medizinIcd: 4,
    agenticToolUse: 3,
    pro: "praxisnah",
    contra: "engl. Bias",
    vramMin: "12 GB",
    vramOptimal: "16 GB",
  },
];
